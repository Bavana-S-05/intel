{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a562e4-066c-4266-b55c-a292d092d42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: intel-extension-for-pytorch==2.2 in ./.local/lib/python3.10/site-packages (2.2.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/lib/python3/dist-packages (from intel-extension-for-pytorch==2.2) (21.3)\n",
      "Collecting psutil\n",
      "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 KB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psutil, numpy\n",
      "\u001b[33m  WARNING: The scripts f2py and numpy-config are installed in '/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.35.2 requires filelock, which is not installed.\n",
      "transformers 4.35.2 requires huggingface-hub<1.0,>=0.16.4, which is not installed.\n",
      "transformers 4.35.2 requires regex!=2019.12.17, which is not installed.\n",
      "transformers 4.35.2 requires safetensors>=0.3.1, which is not installed.\n",
      "transformers 4.35.2 requires tqdm>=4.27, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.3 psutil-7.0.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==4.35.2 in ./.local/lib/python3.10/site-packages (4.35.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers==4.35.2) (5.4.1)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from transformers==4.35.2) (2.2.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers==4.35.2) (2.25.1)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Using cached huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.local/lib/python3.10/site-packages (from transformers==4.35.2) (0.15.2)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers==4.35.2) (21.3)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.12.2)\n",
      "Installing collected packages: tqdm, safetensors, regex, fsspec, filelock, huggingface-hub\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.2.0 requires networkx, which is not installed.\n",
      "torch 2.2.0 requires sympy, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed filelock-3.17.0 fsspec-2025.3.0 huggingface-hub-0.29.2 regex-2024.11.6 safetensors-0.5.3 tqdm-4.67.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch==2.2.0 in ./.local/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch==2.2.0) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (11.4.5.107)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (3.17.0)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (12.1.3.1)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.local/lib/python3.10/site-packages (from torch==2.2.0) (4.12.2)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Using cached nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, nvidia-nvjitlink-cu12, networkx\n",
      "\u001b[33m  WARNING: The script isympy is installed in '/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed mpmath-1.3.0 networkx-3.4.2 nvidia-nvjitlink-cu12-12.8.93 sympy-1.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install intel-extension-for-pytorch==2.2\n",
    "!pip install transformers==4.35.2\n",
    "!pip install torch==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51df5d3-5a15-4d46-bb67-d22fa0b35b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/srv/jupyter/python-venv/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/srv/jupyter/python-venv/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/srv/jupyter/python-venv/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install intel-extension-for-pytorch==2.2 --no-warn-script-location > /dev/null\n",
    "!{sys.executable} -m pip install transformers==4.35.2 --no-warn-script-location > /dev/null\n",
    "!{sys.executable} -m pip install torch==2.2.0 --no-warn-script-location > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea6943c3-5fba-4a63-a051-4208facd34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5240fead-fde7-49db-9cd4-0d6f27b531d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1046, in launch_instance\n",
      "    app.start()\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/srv/jupyter/python-3.11.5/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/srv/jupyter/python-3.11.5/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/srv/jupyter/python-3.11.5/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/srv/jupyter/python-venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2523625/3379815137.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/torch/__init__.py\", line 1471, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import intel_extension_for_pytorch as ipex\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e665de-28a0-407c-8d1f-6f1383c04127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6f2c37e90247e4828b6b21b6f74b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Model='Intel/neural-chat-7b-v3-3'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(Model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e296bc-1bbe-4233-9355-67d87dc0454c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/quantization/_quantize.py:97: UserWarning: BatchNorm folding failed during the prepare process.\n",
      "  warnings.warn(\"BatchNorm folding failed during the prepare process.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipex.llm.optimize is doing the weight only quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/reference/modules/attentions.py:2017: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (input_shape[-1] > 1 or self.sliding_window is not None) and self.is_causal:\n",
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/transformers/modeling_attn_mask_utils.py:137: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/reference/modules/attentions.py:2043: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  else torch.tensor(expanded_attn_mask) + torch.tensor(causal_4d_mask)\n",
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/reference/modules/attentions.py:2043: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  else torch.tensor(expanded_attn_mask) + torch.tensor(causal_4d_mask)\n",
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/reference/fusions/mha_fusion.py:41: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if seq_len is not None and seq_len > self.max_seq_len_cached:\n",
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/cpu/fusions/mha_fusion.py:86: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  seq_info = torch.tensor(\n",
      "/home/ub2189e086da0f20c0dcbaa43d7e904c/.local/lib/python3.11/site-packages/intel_extension_for_pytorch/transformers/models/cpu/fusions/mha_fusion.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seq_info = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipex.llm.optimize has set the optimized or quantization model for model.generate()\n"
     ]
    }
   ],
   "source": [
    "qconfig = ipex.quantization.get_weight_only_quant_qconfig_mapping(\n",
    "    weight_dtype = torch.quint4x2,  #torch.qint8\n",
    "    lowp_mode = ipex.quantization.WoqLowpMode.NONE, #FP16, BF16, INT8\n",
    ")\n",
    "checkpoint=None\n",
    "model_ipex=ipex.llm.optimize(model,quantization_config=qconfig,low_precision_checkpoint=checkpoint)\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a258184-b455-4034-8801-e6ce48d54ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message= \"\"\"\\n\\n You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
    "prompt= \"\\n\\n You are an expert in astronomy. Can you tell me 5 fun facts about the universe?\"\n",
    "model_answer_1 = 'None'\n",
    "\n",
    "prompt_tempate = f\"\"\"\n",
    "### System:\n",
    "{system_message}\n",
    "\n",
    "### User:\n",
    "{prompt}\n",
    "\n",
    "### Assistant:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt_tempate, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "178d5763-e2f6-4a06-89c5-bee29b01e3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) The Universe is expanding at such speeds that if we could travel far enough into space (and time), it would be easier for us to get back home than when we left! This phenomenon was first predicted by Albert Einstein through his theory of general relativity. It has been confirmed with observations from cosmic microwave background radiation data.\n",
      "2) Our Milky Way Galaxy contains over one hundred billion stars - but this number keeps growing because new ones form all the time due to star births within interstellar clouds or remnants after supernovas have exploded. We can only see around two thousand galaxies without using telescopes; however, there may exist more like ten times our own galaxy-counting estimate. So, imagine how many celestial bodies might actually reside out beyond what human eyes perceive now.\n",
      "3) Black holes aren’t just found deep inside massive galactic cores – they also lurk much closer on smaller scales too! In fact, some scientists believe tiny black hole \"seeds\" were created during Big Bang nucleosynthesis which then grew larger via accretion processes later forming stellar systems including planets & life forms themselves…a truly mindboggling concept indeed!\n",
      "4) A single teaspoon full of water weighs approximately five pounds here on Earth—but try imagining its weightlessness under zero gravity conditions where no force pulls downwards anymore...it becomes infinitely lightweight relative to terrest\n"
     ]
    }
   ],
   "source": [
    "streamer = TextStreamer(tokenizer,skip_prompt=True)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    tokens = model_ipex.generate(\n",
    "        inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=300,\n",
    "        repetition_penalty=1.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b1236-6c31-4817-8300-fb1ba3291841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
